---
title: "Multivariate"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{multiOutliers}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(qacOutliers)
```

## What are multivariate outliers? How do you detect them? 

- short description of what they are 
- we will go into how the four methods work in the rest of the vignette

## kNN

kNN calculates the distances between a data point and its k-nearest neighbors, and assigns an outlier score based on that distance. If the outlier score isabove 0.95, then kNN considers the data point as an outlier.

```{r}
multiOutliers(mtcars, method="kNN")
```


## Local outlier factor (LoF)

LoF for a point is the average density around the k-nearest neighbors of the point divided by the density around the point itself. If the  LoF score is above 1, it ts more likely to be anomalous, if it is below 1, it is less likely to be anomalous. 

-describe how this works within our function

```{r}
multiOutliers(mtcarsOutliers, method="LoF")
```

-how to customize results (change threshold and stuff)
-how to intrepret results

## Mahalanobis 

information on the mahalanobis method 

```{r}
multiOutliers(mtcarsOutliers, method="mahalanobis")
```


## iForest 

iForest stands for isolation forest. First, it randomly selects a variable, then randomly selects a value of that variable. This will work for both quantitaive and categorical; if the variable is quantitative, it will randomly pick a number in the range of the variable, and if the variable is categorical it will randomly pick a level. Then it will split the data using the value randomly selected eariler. 

The iForest method repeats the above steps until all points are separately in their own node. Then, for each data point, it counts how many splits were needed to isolate it. 

Because the selection of variables and values is random, this process will return different results each time. Therefore, isolation trees are repeated many times and the results are averaged over all trials. More isolated points will have lower average path lengths. They are more isolated from the rest of the data's distribution, therefore they are called outliers. 

```{r}
multiOutliers(mtcarsOutliers, method="iForest")
```


