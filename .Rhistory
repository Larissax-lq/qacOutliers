<<<<<<< Updated upstream
=======
#removing missing data
if(na.rm) data <- na.omit(data[,varlist])
# Ensure only numeric variables
data <- data[sapply(data, is.numeric)]
# Standardize method argument
method <- match.arg(method, c("kNN", "LoF", "mahalanobis", "iForest"))
# LoF method
if (method == "LoF") {
# Check if data is a matrix or data frame and convert if necessary
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
}
# Remove any non numeric data
data <- data[sapply(data, is.numeric)]
# Ensure the number of points is greater than minPts
if (nrow(data) <= minPts) {
stop("Number of data points must be greater than minPts.")
}
# Normalize the data if not already scaled
data_scaled <- scale(data)
# Apply the LoF method from the dbscan package
>>>>>>> Stashed changes
lof_scores <- dbscan::lof(as.matrix(data_scaled), minPts = minPts)
# Identify outliers based on a threshold (LoF score > 1.5 for stronger outliers)
outlier_indices <- which(lof_scores > 1.5)
outlier_scores <- lof_scores[outlier_indices]
# Prepare results
results <- list(
Method = "LoF",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
minPts = minPts
)
# Set class for consistency with other outlier detection methods
class(results) <- "multiOutliers"
return(results)
<<<<<<< Updated upstream
}
# Mahalanobis method
if (method == "mahalanobis") {
library(dplyr)
=======
}
# Mahalanobis method
if (method == "mahalanobis") {
library(dplyr)
library(Routliers)
# Take only numeric data
numeric_data <- select_if(data, is.numeric)
# Convert to matrix
mat <- as.matrix(numeric_data)
# Run Mahalanobis outlier detection and store results
results <- outliers_mahalanobis(x = mat, alpha = alpha)
#run matrix on function and store results
results <- outliers_mahalanobis(x=mat, alpha=alpha)
index <- results$outliers_pos
# Extract the outlier indices and their Mahalanobis scores
outlier_scores <- results$dist_from_center[index]  # Mahalanobis scores for outliers
# Prepare the result list
output <- list(
Method = "mahalanobis",
Data = dataset_name,          # Store the dataset name
Variables = colnames(numeric_data),  # Store column names of numeric data
Row = index,        # Row numbers of detected outliers
Score = outlier_scores,       # Mahalanobis scores of the detected outliers
alpha = alpha,                # Alpha value used for the detection
Message = if (length(index) == 0) "No outliers detected" else NULL
)
# Assign class and return the result
class(output) <- "multiOutliers"
return(output)
}
# kNN method
if (method == "kNN") {
if (!is.data.frame(data) && !is.matrix(data)) {
stop("Data must be a data frame or matrix.")
}
require(FNN)
# Calculate kNN distances
knn_distances <- knn.dist(data, k = k)
# Calculate the average kNN distance for each row
avg_knn_distances <- rowMeans(knn_distances)
# Define a threshold for detecting outliers
# Outliers are rows with distances greater than a certain threshold
threshold <- mean(avg_knn_distances) + 2 * sd(avg_knn_distances)  # Example: mean + 2 SD
# Identify outliers based on the threshold
outlier_indices <- which(avg_knn_distances > threshold)
outlier_scores <- avg_knn_distances[outlier_indices]
# Create the result list
results <- list(
Method = "kNN",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
k = k
)
class(results) <- "multiOutliers"
return(results)
}
# Isolation Forest (iForest) method
if (method == "iForest") {
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
}
#changing to numeric data
numeric_data <- data[sapply(data[varlist,], is.numeric)]
#running iForest model
isolation_forest_model <- outForest(numeric_data, replace = "no", verbose = 0)
#extract row numbers and scores
outlier_indices <- isolation_forest_model$outliers$row
print(outlier_indices)
outlier_scores <- isolation_forest_model$outliers$score
output <- list(
Method = "iForest",
Data = dataset_name,
Variables = colnames(numeric_data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected"
)
class(output) <- "multiOutliers"
return(output)
}
multiOutliers(irisWithOut, method="iForest")
isolation_forest_model <- outForest(irisWithOut, replace = "no", verbose = 0)
outlier_indices <- isolation_forest_model$outliers$row
outlier_scores <- isolation_forest_model$outliers$score
isolation_forest_model$outliers
outlier_scores
pkgdown:::build_site()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown:::build_site()
??build_site()
pkgdown::build_site(lazy=T)
pkgdown:::build_site()
pkgdown::build_site()
usethis::use_vignette()
usethis::use_vignette("test")
library(iForest)
install.packages("iForest")
library(iForest)
library(outForest)
?outForest
usethis::use_package("FNN")
pkgdown::build_site()
multiOutliers(irisOutliers, method="kNN")
#add in see also and link to other functions that we build our functions off of
multiOutliers <- function(data, varlist = names(data), method, minPts = 10, k = 5, threshold = 0.95, alpha = 0.1, na.rm = TRUE, ...) {
# Get the dataset name
dataset_name <- deparse(substitute(data))
#removing missing data
if(na.rm) data <- na.omit(data[,varlist])
# Standardize method argument
method <- match.arg(method, c("kNN", "LoF", "mahalanobis", "iForest"))
# LoF method
if (method == "LoF") {
# Check if data is a matrix or data frame and convert if necessary
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
}
# Ensure the number of points is greater than minPts
if (nrow(data) <= minPts) {
stop("Number of data points must be greater than minPts.")
}
# Normalize the data if not already scaled
data_scaled <- scale(data)
# Apply the LoF method from the dbscan package
lof_scores <- dbscan::lof(as.matrix(data_scaled), minPts = minPts)
# Identify outliers based on a threshold (LoF score > 1.5 for stronger outliers)
outlier_indices <- which(lof_scores > 1.5)
outlier_scores <- lof_scores[outlier_indices]
# Prepare results
results <- list(
Method = "LoF",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
minPts = minPts
)
# Set class for consistency with other outlier detection methods
class(results) <- "multiOutliers"
return(results)
}
# Mahalanobis method
if (method == "mahalanobis") {
library(dplyr)
library(Routliers)
#take only numeric data
numeric_data <- select_if(data[,varlist], is.numeric)
#convert to matrix
mat <- as.matrix(numeric_data)
#run matrix on function and store results
results <- outliers_mahalanobis(x=mat, alpha=alpha)
index <- results$outliers_pos
#extract the outlier indices and their Mahalanobis scores
outlier_scores <- results$dist_from_center[index]  # Mahalanobis scores for outliers
#prepare the result list
output <- list(
Method = "mahalanobis",
Data = dataset_name,          # Store the dataset name
Variables = colnames(numeric_data),  # Store column names of numeric data
Row = index,        # Row numbers of detected outliers
Score = outlier_scores,       # Mahalanobis scores of the detected outliers
Message = if (length(index) == 0) "No outliers detected" else "Outliers detected",
alpha = alpha
)
#assign class and return the result
class(output) <- "multiOutliers"
return(output)
}
# kNN method
if (method == "kNN") {
if (!is.data.frame(data) && !is.matrix(data)) {
stop("Data must be a data frame or matrix.")
}
require(FNN)
# Calculate kNN distances
knn_distances <- knn.dist(data[,varlist], k = k)
# Calculate the average kNN distance for each row
avg_knn_distances <- rowMeans(knn_distances)
# Define a threshold for detecting outliers
# Outliers are rows with distances greater than a certain threshold
threshold <- mean(avg_knn_distances) + 2 * sd(avg_knn_distances)  # Example: mean + 2 SD
# Identify outliers based on the threshold
outlier_indices <- which(avg_knn_distances > threshold)
outlier_scores <- avg_knn_distances[outlier_indices]
# Create the result list
results <- list(
Method = "kNN",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
k = k
)
class(results) <- "multiOutliers"
return(results)
}
# Isolation Forest (iForest) method
if (method == "iForest") {
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
}
#changing to numeric data
numeric_data <- data[sapply(data[,varlist], is.numeric)]
#running iForest model
isolation_forest_model <- outForest(numeric_data, replace = "no", verbose = 0)
#extract row numbers and scores
outlier_indices <- isolation_forest_model$outliers$row
outlier_scores <- isolation_forest_model$outliers$score
output <- list(
Method = "iForest",
Data = dataset_name,
Variables = colnames(numeric_data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected"
)
class(output) <- "multiOutliers"
return(output)
}
multiOutliers(irisOutliers, method="LoF")
#add in see also and link to other functions that we build our functions off of
multiOutliers <- function(data, varlist = names(data), method, minPts = 10, k = 5, threshold = 0.95, alpha = 0.1, na.rm = TRUE, ...) {
# Get the dataset name
dataset_name <- deparse(substitute(data))
#removing missing data
if(na.rm) data <- na.omit(data[,varlist])
# Remove any non numeric data
data <- data[sapply(data[,varlist], is.numeric)]
# Standardize method argument
method <- match.arg(method, c("kNN", "LoF", "mahalanobis", "iForest"))
# LoF method
if (method == "LoF") {
# Check if data is a matrix or data frame and convert if necessary
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
}
# Ensure the number of points is greater than minPts
if (nrow(data) <= minPts) {
stop("Number of data points must be greater than minPts.")
}
# Normalize the data if not already scaled
data_scaled <- scale(data)
# Apply the LoF method from the dbscan package
lof_scores <- dbscan::lof(as.matrix(data_scaled), minPts = minPts)
# Identify outliers based on a threshold (LoF score > 1.5 for stronger outliers)
outlier_indices <- which(lof_scores > 1.5)
outlier_scores <- lof_scores[outlier_indices]
# Prepare results
results <- list(
Method = "LoF",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
minPts = minPts
)
# Set class for consistency with other outlier detection methods
class(results) <- "multiOutliers"
return(results)
}
# Mahalanobis method
if (method == "mahalanobis") {
library(dplyr)
library(Routliers)
#convert to matrix
mat <- as.matrix(data)
#run matrix on function and store results
results <- outliers_mahalanobis(x=mat, alpha=alpha)
index <- results$outliers_pos
#extract the outlier indices and their Mahalanobis scores
outlier_scores <- results$dist_from_center[index]  # Mahalanobis scores for outliers
#prepare the result list
output <- list(
Method = "mahalanobis",
Data = dataset_name,          # Store the dataset name
Variables = colnames(numeric_data),  # Store column names of numeric data
Row = index,        # Row numbers of detected outliers
Score = outlier_scores,       # Mahalanobis scores of the detected outliers
Message = if (length(index) == 0) "No outliers detected" else "Outliers detected",
alpha = alpha
)
#assign class and return the result
class(output) <- "multiOutliers"
return(output)
}
# kNN method
if (method == "kNN") {
if (!is.data.frame(data) && !is.matrix(data)) {
stop("Data must be a data frame or matrix.")
}
require(FNN)
# Calculate kNN distances
knn_distances <- knn.dist(data, k = k)
# Calculate the average kNN distance for each row
avg_knn_distances <- rowMeans(knn_distances)
# Define a threshold for detecting outliers
# Outliers are rows with distances greater than a certain threshold
threshold <- mean(avg_knn_distances) + 2 * sd(avg_knn_distances)  # Example: mean + 2 SD
# Identify outliers based on the threshold
outlier_indices <- which(avg_knn_distances > threshold)
outlier_scores <- avg_knn_distances[outlier_indices]
# Create the result list
results <- list(
Method = "kNN",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
k = k
)
class(results) <- "multiOutliers"
return(results)
}
# Isolation Forest (iForest) method
if (method == "iForest") {
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
}
#running iForest model
isolation_forest_model <- outForest(numeric_data, replace = "no", verbose = 0)
#extract row numbers and scores
outlier_indices <- isolation_forest_model$outliers$row
outlier_scores <- isolation_forest_model$outliers$score
output <- list(
Method = "iForest",
Data = dataset_name,
Variables = colnames(numeric_data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected"
)
class(output) <- "multiOutliers"
return(output)
}
multiOutliers(irisOutliers, method="kNN")
univOutliers <- function(data, x = NULL, method = "boxplot") {
# Identify numeric columns in the dataset
numeric_columns <- sapply(data, is.numeric)
# Suppressing warnings
options(warn = -1)
# If 'x' is not specified, use all numeric columns in the dataset
if (is.null(x)) {
x <- names(data)[numeric_columns]
} else {
if (!x %in% names(data)) stop(paste("The specified column", x, "does not exist in the data frame."))
x <- list(x)
}
# Loop through each numeric variable specified in 'x'
for (column in x) {
column_data <- na.omit(data[[column]])  # Remove NA values from the column
# Print the method being used
cat("\nUsing", method, "method for", column, "\n")
# Boxplot Method
if (method == "boxplot") {
stats <- boxplot.stats(column_data)
if (length(stats$out) == 0) {
cat("No outliers detected for", column, "\n")
} else {
cat("Outliers detected for", column, ":\n")
outlier_rows <- which(data[[column]] %in% stats$out)
for (i in outlier_rows) {
cat("Row", i, ":", data[[column]][i], "\n")
}
# Create the ggplot boxplot (optional, only for visualization)
library(ggplot2)
p <- ggplot(data, aes(y = .data[[column]])) +
geom_boxplot(outlier.colour = "red", coef = 1.58) +
ggtitle(paste("Univariate Boxplot of", column)) +
theme_minimal()
print(p)
}
# MAD Method
else if (method == "mad") {
>>>>>>> Stashed changes
library(Routliers)
# Take only numeric data
numeric_data <- select_if(data, is.numeric)
# Convert to matrix
mat <- as.matrix(numeric_data)
# Run Mahalanobis outlier detection and store results
results <- outliers_mahalanobis(x = mat, alpha = alpha)
#run matrix on function and store results
results <- outliers_mahalanobis(x=mat, alpha=alpha)
index <- results$outliers_pos
# Extract the outlier indices and their Mahalanobis scores
outlier_scores <- results$dist_from_center[index]  # Mahalanobis scores for outliers
# Prepare the result list
output <- list(
Method = "mahalanobis",
Data = dataset_name,          # Store the dataset name
Variables = colnames(numeric_data),  # Store column names of numeric data
Row = index,        # Row numbers of detected outliers
Score = outlier_scores,       # Mahalanobis scores of the detected outliers
alpha = alpha,                # Alpha value used for the detection
Message = if (length(index) == 0) "No outliers detected" else NULL
)
# Assign class and return the result
class(output) <- "multiOutliers"
return(output)
}
<<<<<<< Updated upstream
# kNN method
if (method == "kNN") {
if (!is.data.frame(data) && !is.matrix(data)) {
stop("Data must be a data frame or matrix.")
}
require(FNN)
# Calculate kNN distances
knn_distances <- knn.dist(data, k = k)
# Calculate the average kNN distance for each row
avg_knn_distances <- rowMeans(knn_distances)
# Define a threshold for detecting outliers
# Outliers are rows with distances greater than a certain threshold
threshold <- mean(avg_knn_distances) + 2 * sd(avg_knn_distances)  # Example: mean + 2 SD
# Identify outliers based on the threshold
outlier_indices <- which(avg_knn_distances > threshold)
outlier_scores <- avg_knn_distances[outlier_indices]
# Create the result list
results <- list(
Method = "kNN",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
k = k
)
class(results) <- "multiOutliers"
return(results)
}
# Isolation Forest (iForest) method
if (method == "iForest") {
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
=======
# Plot the outliers using plot_outliers_mad
plot_outliers_mad(res1, data[[column]], pos_display = FALSE)
}
# Grubbs' Test Method
else if (method == "grubbs") {
# Q-Q plot before running Grubbs' test
qqnorm(column_data, main = paste("Q-Q Plot for", column))
qqline(column_data, col = "red")
# Grubbs' test function
grubbs_test <- function(data, alpha = 0.05) {
data <- na.omit(data)  # Remove NA values
if (!is.numeric(data)) stop("Input data must be numeric.")
if (length(data) < 3) stop("Data must contain at least three points for Grubbs' test.")
# Normality check
normality_test <- shapiro.test(data)
if (normality_test$p.value < 0.05) {
warning("Data is not normally distributed. Grubbs' test may not be appropriate.")
>>>>>>> Stashed changes
}
#changing to numeric data
numeric_data <- data[sapply(data[,varlist], is.numeric)]
print(numeric_data)
#running iForest model
isolation_forest_model <- outForest(numeric_data, replace = "no", verbose = 0)
print(isolation_forest_model)
#extract row numbers and scores
outlier_indices <- as.numeric(rownames(isolation_forest_model$outliers))
print(outlier_indices)
outlier_scores <- isolation_forest_model$outliers$score
print(outlier_scores)
output <- list(
Method = "iForest",
Data = dataset_name,
Variables = colnames(numeric_data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected"
)
class(output) <- "multiOutliers"
return(output)
}
<<<<<<< Updated upstream
multiOutliers(irisWithOut, method="iForest")
multiOutliers <- function(data, varlist = names(data), method, minPts = 10, k = 5, threshold = 0.95, alpha = 0.1, na.rm = TRUE, ...) {
# Get the dataset name
dataset_name <- deparse(substitute(data))
#surpressing warnings
options(warn = -1)
#removing missing data
if(na.rm) data <- na.omit(data[,varlist])
# Ensure only numeric variables
data <- data[sapply(data, is.numeric)]
# Standardize method argument
method <- match.arg(method, c("kNN", "LoF", "mahalanobis", "iForest"))
# LoF method
if (method == "LoF") {
# Check if data is a matrix or data frame and convert if necessary
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
}
# Remove any non numeric data
data <- data[sapply(data, is.numeric)]
# Ensure the number of points is greater than minPts
if (nrow(data) <= minPts) {
stop("Number of data points must be greater than minPts.")
}
# Normalize the data if not already scaled
data_scaled <- scale(data)
# Apply the LoF method from the dbscan package
lof_scores <- dbscan::lof(as.matrix(data_scaled), minPts = minPts)
# Identify outliers based on a threshold (LoF score > 1.5 for stronger outliers)
outlier_indices <- which(lof_scores > 1.5)
outlier_scores <- lof_scores[outlier_indices]
# Prepare results
results <- list(
Method = "LoF",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
minPts = minPts
)
# Set class for consistency with other outlier detection methods
class(results) <- "multiOutliers"
return(results)
}
# Mahalanobis method
if (method == "mahalanobis") {
library(dplyr)
library(Routliers)
# Take only numeric data
numeric_data <- select_if(data, is.numeric)
# Convert to matrix
mat <- as.matrix(numeric_data)
# Run Mahalanobis outlier detection and store results
results <- outliers_mahalanobis(x = mat, alpha = alpha)
#run matrix on function and store results
results <- outliers_mahalanobis(x=mat, alpha=alpha)
index <- results$outliers_pos
# Extract the outlier indices and their Mahalanobis scores
outlier_scores <- results$dist_from_center[index]  # Mahalanobis scores for outliers
# Prepare the result list
output <- list(
Method = "mahalanobis",
Data = dataset_name,          # Store the dataset name
Variables = colnames(numeric_data),  # Store column names of numeric data
Row = index,        # Row numbers of detected outliers
Score = outlier_scores,       # Mahalanobis scores of the detected outliers
alpha = alpha,                # Alpha value used for the detection
Message = if (length(index) == 0) "No outliers detected" else NULL
)
# Assign class and return the result
class(output) <- "multiOutliers"
return(output)
}
# kNN method
if (method == "kNN") {
if (!is.data.frame(data) && !is.matrix(data)) {
stop("Data must be a data frame or matrix.")
}
require(FNN)
# Calculate kNN distances
knn_distances <- knn.dist(data, k = k)
# Calculate the average kNN distance for each row
avg_knn_distances <- rowMeans(knn_distances)
# Define a threshold for detecting outliers
# Outliers are rows with distances greater than a certain threshold
threshold <- mean(avg_knn_distances) + 2 * sd(avg_knn_distances)  # Example: mean + 2 SD
# Identify outliers based on the threshold
outlier_indices <- which(avg_knn_distances > threshold)
outlier_scores <- avg_knn_distances[outlier_indices]
# Create the result list
results <- list(
Method = "kNN",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
k = k
)
class(results) <- "multiOutliers"
return(results)
}
# Isolation Forest (iForest) method
if (method == "iForest") {
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
}
#changing to numeric data
numeric_data <- data[sapply(data[varlist,], is.numeric)]
print(numeric_data)
#running iForest model
isolation_forest_model <- outForest(numeric_data, replace = "no", verbose = 0)
print(isolation_forest_model)
#extract row numbers and scores
outlier_indices <- as.numeric(rownames(isolation_forest_model$outliers))
print(outlier_indices)
outlier_scores <- isolation_forest_model$outliers$score
print(outlier_scores)
output <- list(
Method = "iForest",
Data = dataset_name,
Variables = colnames(numeric_data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected"
)
class(output) <- "multiOutliers"
return(output)
}
multiOutliers(irisWithOut, method="iForest")
multiOutliers <- function(data, varlist = names(data), method, minPts = 10, k = 5, threshold = 0.95, alpha = 0.1, na.rm = TRUE, ...) {
# Get the dataset name
dataset_name <- deparse(substitute(data))
#surpressing warnings
options(warn = -1)
#removing missing data
if(na.rm) data <- na.omit(data[,varlist])
# Ensure only numeric variables
data <- data[sapply(data, is.numeric)]
# Standardize method argument
method <- match.arg(method, c("kNN", "LoF", "mahalanobis", "iForest"))
# LoF method
if (method == "LoF") {
# Check if data is a matrix or data frame and convert if necessary
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
}
# Remove any non numeric data
data <- data[sapply(data, is.numeric)]
# Ensure the number of points is greater than minPts
if (nrow(data) <= minPts) {
stop("Number of data points must be greater than minPts.")
}
# Normalize the data if not already scaled
data_scaled <- scale(data)
# Apply the LoF method from the dbscan package
lof_scores <- dbscan::lof(as.matrix(data_scaled), minPts = minPts)
# Identify outliers based on a threshold (LoF score > 1.5 for stronger outliers)
outlier_indices <- which(lof_scores > 1.5)
outlier_scores <- lof_scores[outlier_indices]
# Prepare results
results <- list(
Method = "LoF",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
minPts = minPts
)
# Set class for consistency with other outlier detection methods
class(results) <- "multiOutliers"
return(results)
}
# Mahalanobis method
if (method == "mahalanobis") {
library(dplyr)
library(Routliers)
# Take only numeric data
numeric_data <- select_if(data, is.numeric)
# Convert to matrix
mat <- as.matrix(numeric_data)
# Run Mahalanobis outlier detection and store results
results <- outliers_mahalanobis(x = mat, alpha = alpha)
#run matrix on function and store results
results <- outliers_mahalanobis(x=mat, alpha=alpha)
index <- results$outliers_pos
# Extract the outlier indices and their Mahalanobis scores
outlier_scores <- results$dist_from_center[index]  # Mahalanobis scores for outliers
# Prepare the result list
output <- list(
Method = "mahalanobis",
Data = dataset_name,          # Store the dataset name
Variables = colnames(numeric_data),  # Store column names of numeric data
Row = index,        # Row numbers of detected outliers
Score = outlier_scores,       # Mahalanobis scores of the detected outliers
alpha = alpha,                # Alpha value used for the detection
Message = if (length(index) == 0) "No outliers detected" else NULL
)
# Assign class and return the result
class(output) <- "multiOutliers"
return(output)
}
# kNN method
if (method == "kNN") {
if (!is.data.frame(data) && !is.matrix(data)) {
stop("Data must be a data frame or matrix.")
}
require(FNN)
# Calculate kNN distances
knn_distances <- knn.dist(data, k = k)
# Calculate the average kNN distance for each row
avg_knn_distances <- rowMeans(knn_distances)
# Define a threshold for detecting outliers
# Outliers are rows with distances greater than a certain threshold
threshold <- mean(avg_knn_distances) + 2 * sd(avg_knn_distances)  # Example: mean + 2 SD
# Identify outliers based on the threshold
outlier_indices <- which(avg_knn_distances > threshold)
outlier_scores <- avg_knn_distances[outlier_indices]
# Create the result list
results <- list(
Method = "kNN",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
k = k
)
class(results) <- "multiOutliers"
return(results)
}
# Isolation Forest (iForest) method
if (method == "iForest") {
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
}
#changing to numeric data
numeric_data <- data[sapply(data[varlist,], is.numeric)]
print(numeric_data)
#running iForest model
isolation_forest_model <- outForest(numeric_data, replace = "no", verbose = 0)
print(isolation_forest_model)
#extract row numbers and scores
outlier_indices <- 1:nrow(isolation_forest_model$outliers)
print(outlier_indices)
outlier_scores <- isolation_forest_model$outliers$score
print(outlier_scores)
output <- list(
Method = "iForest",
Data = dataset_name,
Variables = colnames(numeric_data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected"
)
class(output) <- "multiOutliers"
return(output)
}
multiOutliers(irisWithOut, method="iForest")
multiOutliers <- function(data, varlist = names(data), method, minPts = 10, k = 5, threshold = 0.95, alpha = 0.1, na.rm = TRUE, ...) {
# Get the dataset name
dataset_name <- deparse(substitute(data))
#surpressing warnings
options(warn = -1)
#removing missing data
if(na.rm) data <- na.omit(data[,varlist])
# Ensure only numeric variables
data <- data[sapply(data, is.numeric)]
# Standardize method argument
method <- match.arg(method, c("kNN", "LoF", "mahalanobis", "iForest"))
# LoF method
if (method == "LoF") {
# Check if data is a matrix or data frame and convert if necessary
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
}
# Remove any non numeric data
data <- data[sapply(data, is.numeric)]
# Ensure the number of points is greater than minPts
if (nrow(data) <= minPts) {
stop("Number of data points must be greater than minPts.")
}
# Normalize the data if not already scaled
data_scaled <- scale(data)
# Apply the LoF method from the dbscan package
lof_scores <- dbscan::lof(as.matrix(data_scaled), minPts = minPts)
# Identify outliers based on a threshold (LoF score > 1.5 for stronger outliers)
outlier_indices <- which(lof_scores > 1.5)
outlier_scores <- lof_scores[outlier_indices]
# Prepare results
results <- list(
Method = "LoF",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
minPts = minPts
)
# Set class for consistency with other outlier detection methods
class(results) <- "multiOutliers"
return(results)
}
# Mahalanobis method
if (method == "mahalanobis") {
library(dplyr)
library(Routliers)
# Take only numeric data
numeric_data <- select_if(data, is.numeric)
# Convert to matrix
mat <- as.matrix(numeric_data)
# Run Mahalanobis outlier detection and store results
results <- outliers_mahalanobis(x = mat, alpha = alpha)
#run matrix on function and store results
results <- outliers_mahalanobis(x=mat, alpha=alpha)
index <- results$outliers_pos
# Extract the outlier indices and their Mahalanobis scores
outlier_scores <- results$dist_from_center[index]  # Mahalanobis scores for outliers
# Prepare the result list
output <- list(
Method = "mahalanobis",
Data = dataset_name,          # Store the dataset name
Variables = colnames(numeric_data),  # Store column names of numeric data
Row = index,        # Row numbers of detected outliers
Score = outlier_scores,       # Mahalanobis scores of the detected outliers
alpha = alpha,                # Alpha value used for the detection
Message = if (length(index) == 0) "No outliers detected" else NULL
)
# Assign class and return the result
class(output) <- "multiOutliers"
return(output)
}
# kNN method
if (method == "kNN") {
if (!is.data.frame(data) && !is.matrix(data)) {
stop("Data must be a data frame or matrix.")
}
require(FNN)
# Calculate kNN distances
knn_distances <- knn.dist(data, k = k)
# Calculate the average kNN distance for each row
avg_knn_distances <- rowMeans(knn_distances)
# Define a threshold for detecting outliers
# Outliers are rows with distances greater than a certain threshold
threshold <- mean(avg_knn_distances) + 2 * sd(avg_knn_distances)  # Example: mean + 2 SD
# Identify outliers based on the threshold
outlier_indices <- which(avg_knn_distances > threshold)
outlier_scores <- avg_knn_distances[outlier_indices]
# Create the result list
results <- list(
Method = "kNN",
Data = dataset_name,
Variables = colnames(data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected",
k = k
)
class(results) <- "multiOutliers"
return(results)
}
# Isolation Forest (iForest) method
if (method == "iForest") {
if (!is.matrix(data) && !is.data.frame(data)) {
stop("Data should be a matrix or data frame.")
}
#changing to numeric data
numeric_data <- data[sapply(data[varlist,], is.numeric)]
#running iForest model
isolation_forest_model <- outForest(numeric_data, replace = "no", verbose = 0)
#extract row numbers and scores
outlier_indices <- isolation_forest_model$outliers$row
print(outlier_indices)
outlier_scores <- isolation_forest_model$outliers$score
output <- list(
Method = "iForest",
Data = dataset_name,
Variables = colnames(numeric_data),
Row = outlier_indices,
Score = outlier_scores,
Message = if (length(outlier_indices) == 0) "No outliers detected" else "Outliers detected"
)
class(output) <- "multiOutliers"
return(output)
}
multiOutliers(irisWithOut, method="iForest")
isolation_forest_model <- outForest(irisWithOut, replace = "no", verbose = 0)
outlier_indices <- isolation_forest_model$outliers$row
outlier_scores <- isolation_forest_model$outliers$score
isolation_forest_model$outliers
outlier_scores
pkgdown:::build_site()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown:::build_site()
??build_site()
pkgdown::build_site(lazy=T)
pkgdown:::build_site()
pkgdown::build_site()
usethis::use_vignette()
usethis::use_vignette("test")
library(iForest)
install.packages("iForest")
library(iForest)
library(outForest)
?outForest
usethis::use_package("FNN")
=======
if (length(current_data) < 3) break
}
# Identify the rows of outliers
outlier_rows <- which(data %in% outliers)
return(list(outliers = unique(outliers), outlier_rows = outlier_rows))
}
result <- grubbs_test(column_data)
cat("Outliers detected for", column, ":\n")
if (length(result$outliers) == 0) {
cat("No outliers detected for", column, "\n")
} else {
for (i in result$outlier_rows) {
cat("Row", i, ":", data[[column]][i], "\n")
}
} else {
stop("Invalid method. Choose from 'boxplot', 'mad', or 'grubbs'.")
}
print.univOutliers <- function(results, method) {
# Print the method being used
cat("Outlier detection using", method, "method\n\n")
# Loop through the results for each variable
for (column in names(results)) {
result <- results[[column]]
# Check if outliers were detected
if (length(result$outliers) > 0) {
cat("Outliers detected for", column, ":\n")
for (i in seq_along(result$outliers)) {
cat("Row", result$outlier_rows[i], ":", result$outliers[i], "\n")
}
} else {
cat("No outliers detected for", column, "\n")
}
cat("\n")  # Add a newline between columns for readability
}
set.seed(42)
data1 <- data.frame(
var1 = rnorm(100, mean = 50, sd = 10),
var2 = c(rnorm(97, mean = 50, sd = 10), 150, 160, 170),
var3 = sample(1:100, 100, replace = TRUE, prob = (1:100)^2))
results <- univOutliers(data1, method = "boxplot")
results <- univOutliers(data1, "var1", method = "boxplot")
results <- univOutliers(data1, method = "grubbs")
results <- univOutliers(data1, "var1", method = "grubbs")
results <- univOutliers(data1, method = "mad")
results <- univOutliers(data1, "var1", method = "mad")
results <- univOutliers(data1, method = "mad")
>>>>>>> Stashed changes
